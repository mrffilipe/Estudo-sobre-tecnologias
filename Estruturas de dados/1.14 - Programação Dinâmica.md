### **Programação Dinâmica**

Programação Dinâmica (Dynamic Programming - DP) é uma técnica de otimização poderosa para resolver problemas que podem ser decompostos em subproblemas sobrepostos. A ideia central é evitar cálculos redundantes, armazenando os resultados de subproblemas já resolvidos. Vamos explorar os tópicos relacionados à DP.

---

### **14.1 Rod Cutting (Problema do Corte de Barras)**

O problema do corte de barras busca determinar o melhor modo de cortar uma barra de comprimento \( n \) para maximizar o lucro, dado um preço \( p[i] \) para cada comprimento \( i \).

##### **Definição do Problema**
- **Entrada**: Um número inteiro \( n \) (comprimento da barra) e uma tabela \( p[1..n] \) com os preços.
- **Saída**: O valor máximo de lucro \( r[n] \) que pode ser obtido cortando a barra.

##### **Formulação Recursiva**
O lucro máximo \( r[n] \) pode ser definido como:
\[
r[n] = \max_{1 \leq i \leq n} (p[i] + r[n - i])
\]
onde \( r[0] = 0 \).

##### **Solução com DP**
Em vez de resolver repetidamente os mesmos subproblemas, usamos uma abordagem de memoização ou tabulação:
1. **Memoização**: Armazena resultados em um array para evitar cálculos redundantes.
2. **Tabulação**: Resolve os subproblemas menores primeiro e os usa para construir a solução dos maiores.

##### **Pseudocódigo**
```pseudo
ROD-CUTTING(p, n):
    let r[0..n] = 0
    for j = 1 to n:
        q = -∞
        for i = 1 to j:
            q = max(q, p[i] + r[j - i])
        r[j] = q
    return r[n]
```

##### **Complexidade**
- **Tempo**: \( O(n^2) \), devido ao loop aninhado.
- **Espaço**: \( O(n) \).

---

### **14.2 Multiplicação de Cadeias de Matrizes**

O problema de **Matrix-Chain Multiplication** busca determinar a ordem ótima para multiplicar \( n \) matrizes \( A_1, A_2, \dots, A_n \) para minimizar o número de operações escalares.

##### **Definição do Problema**
- Cada matriz \( A_i \) tem dimensões \( p[i-1] \times p[i] \).
- O custo de multiplicar \( A_i \times A_j \) é dado por \( p[i-1] \times p[i] \times p[j] \).

##### **Formulação Recursiva**
Definimos \( m[i, j] \) como o número mínimo de multiplicações para computar \( A_i \times \dots \times A_j \):
\[
m[i, j] = \min_{i \leq k < j} \{ m[i, k] + m[k+1, j] + p[i-1] \times p[k] \times p[j] \}
\]
onde \( m[i, i] = 0 \).

##### **Solução com DP**
1. Calcular \( m[i, j] \) para subsequências curtas (\( j - i = 1 \)) antes das longas.
2. Usar os resultados dos subproblemas para calcular os mais complexos.

##### **Pseudocódigo**
```pseudo
MATRIX-CHAIN-ORDER(p):
    let n = length(p) - 1
    let m[1..n, 1..n] = 0
    for l = 2 to n:  // Comprimento da subsequência
        for i = 1 to n-l+1:
            j = i + l - 1
            m[i, j] = ∞
            for k = i to j-1:
                q = m[i, k] + m[k+1, j] + p[i-1] * p[k] * p[j]
                if q < m[i, j]:
                    m[i, j] = q
    return m
```

##### **Complexidade**
- **Tempo**: \( O(n^3) \).
- **Espaço**: \( O(n^2) \).

---

### **14.3 Elementos da Programação Dinâmica**

##### **Estrutura do Problema**
Para usar DP, um problema deve possuir:
1. **Subproblemas sobrepostos**:
   - O problema maior pode ser resolvido a partir de problemas menores.
2. **Propriedade ótima**:
   - A solução de um subproblema é usada diretamente para construir a solução global.

##### **Métodos de Implementação**
1. **Top-Down com Memoização**:
   - Resolução recursiva, armazenando os resultados para evitar redundância.
2. **Bottom-Up com Tabulação**:
   - Resolve subproblemas menores primeiro e usa esses resultados para problemas maiores.

##### **Vantagens**
- Eficiência no tempo de execução.
- Evita redundância, economizando processamento.

---

### **14.4 Subsequência Comum Mais Longa (LCS)**

O problema da **Longest Common Subsequence (LCS)** busca encontrar a maior subsequência comum entre duas strings \( X \) e \( Y \).

##### **Definição do Problema**
- **Entrada**: Duas strings \( X \) de tamanho \( m \) e \( Y \) de tamanho \( n \).
- **Saída**: O comprimento da maior subsequência comum.

##### **Formulação Recursiva**
Definimos \( c[i, j] \) como o comprimento do LCS das primeiras \( i \) letras de \( X \) e \( j \) letras de \( Y \):
\[
c[i, j] = 
\begin{cases} 
0 & \text{se } i = 0 \text{ ou } j = 0 \\
c[i-1, j-1] + 1 & \text{se } X[i] = Y[j] \\
\max(c[i-1, j], c[i, j-1]) & \text{caso contrário.}
\end{cases}
\]

##### **Pseudocódigo**
```pseudo
LCS(X, Y):
    let m = length(X)
    let n = length(Y)
    let c[0..m, 0..n] = 0
    for i = 1 to m:
        for j = 1 to n:
            if X[i] == Y[j]:
                c[i, j] = c[i-1, j-1] + 1
            else:
                c[i, j] = max(c[i-1, j], c[i, j-1])
    return c[m, n]
```

##### **Complexidade**
- **Tempo**: \( O(mn) \).
- **Espaço**: \( O(mn) \) (pode ser reduzido para \( O(\min(m, n)) \)).

---

### **14.5 Árvores de Busca Binária Ótimas**

No problema de **Optimal Binary Search Tree (OBST)**, buscamos construir uma árvore de busca binária que minimize o custo esperado de busca.

##### **Definição do Problema**
- Dada uma sequência de \( n \) chaves ordenadas \( K = \{k_1, k_2, \dots, k_n\} \) com probabilidades de acesso \( P = \{p_1, p_2, \dots, p_n\} \), construir uma árvore de busca binária com custo esperado mínimo.

##### **Formulação Recursiva**
O custo \( e[i, j] \) da árvore ótima para \( k_i \) a \( k_j \) é:
\[
e[i, j] = \min_{r=i}^{j} \{ e[i, r-1] + e[r+1, j] + \text{soma das probabilidades entre } i \text{ e } j \}
\]
onde \( e[i, i-1] = 0 \) e \( e[i, i] = p_i \).

##### **Pseudocódigo**
```pseudo
OPTIMAL-BST(P, n):
    let e[1..n+1, 0..n] = 0
    let w[1..n+1, 0..n] = 0
    for l = 1 to n:  // Comprimento
        for i = 1 to n-l+1:
            j = i + l - 1
            e[i, j] = ∞
            w[i, j] = w[i, j-1] + p[j]
            for r = i to j:
                q = e[i, r-1] + e[r+1, j] + w[i, j]
                if q < e[i, j]:
                    e[i, j] = q
    return e[1, n]
```

##### **Complexidade**
- **Tempo**: \( O(n^3) \).
- **Espaço**: \( O(n^2) \).

---

### **Conclusão**

A Programação Dinâmica é uma técnica fundamental para resolver problemas com subproblemas sobrepostos e propriedades ótimas. Com exemplos clássicos como Rod Cutting, LCS, e OB

ST, ela mostra sua aplicabilidade em diversas áreas, desde algoritmos teóricos até aplicações práticas.